# Path: src/data_builder/writer.py
import csv
import sqlite3
import os
import logging
from typing import List
from src.data_builder.models import SegmentData

logger = logging.getLogger(__name__)

__all__ = ["DataWriter"]

class DataWriter:
    def __init__(self, tsv_path: str, db_path: str):
        self.tsv_path = tsv_path
        self.db_path = db_path

    def save(self, data: List[SegmentData]) -> None:
        self._save_tsv(data)
        self._save_sqlite(data)

    def _save_tsv(self, data: List[SegmentData]) -> None:
        os.makedirs(os.path.dirname(self.tsv_path), exist_ok=True)
        with open(self.tsv_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=["uid", "html", "label", "segment", "audio"], delimiter='\t')
            writer.writeheader()
            for item in data:
                writer.writerow(item.model_dump())
        logger.info(f"âœ… ÄÃ£ lÆ°u TSV táº¡i: {self.tsv_path}")

    def _save_sqlite(self, data: List[SegmentData]) -> None:
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        
        # [UPDATED] Ghi vÃ o file táº¡m trÆ°á»›c Ä‘á»ƒ so sÃ¡nh ná»™i dung
        temp_db_path = self.db_path + ".tmp"
        if os.path.exists(temp_db_path):
            os.remove(temp_db_path)

        # Káº¿t ná»‘i tá»›i file táº¡m
        conn = sqlite3.connect(temp_db_path)
        cursor = conn.cursor()
        
        # Táº¡o báº£ng pháº³ng
        cursor.execute("""
            CREATE TABLE contents (
                uid INTEGER PRIMARY KEY,
                html TEXT,
                label TEXT,
                segment TEXT,
                audio TEXT
            )
        """)
        
        # Insert dá»¯ liá»‡u
        insert_data = [tuple(item.model_dump().values()) for item in data]
        cursor.executemany("INSERT INTO contents VALUES (?, ?, ?, ?, ?)", insert_data)
        
        conn.commit()
        conn.close()

        # [LOGIC] So sÃ¡nh file táº¡m vÃ  file chÃ­nh
        if os.path.exists(self.db_path) and self._files_are_identical(self.db_path, temp_db_path):
            logger.info("ğŸ’¤ DB ná»™i dung khÃ´ng thay Ä‘á»•i. Giá»¯ nguyÃªn file cÅ© (Ä‘á»ƒ báº£o toÃ n timestamp).")
            os.remove(temp_db_path)
        else:
            if os.path.exists(self.db_path):
                logger.info("â™»ï¸  DB cÃ³ thay Ä‘á»•i. Äang cáº­p nháº­t file má»›i...")
                os.remove(self.db_path)
            else:
                logger.info("âœ¨ Táº¡o má»›i DB láº§n Ä‘áº§u.")
            os.rename(temp_db_path, self.db_path)
            logger.info(f"âœ… ÄÃ£ lÆ°u SQLite DB táº¡i: {self.db_path}")

        # [NEW] Táº¡o file version Ä‘á»ƒ frontend burst cache
        self._save_version_file()

    def _save_version_file(self) -> None:
        import json
        import time
        import hashlib
        
        # 1. TÃ­nh hash cá»§a file DB hiá»‡n táº¡i
        with open(self.db_path, "rb") as f:
            db_hash = hashlib.md5(f.read()).hexdigest()
            
        # 2. XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n file version
        db_filename = os.path.basename(self.db_path)
        version_filename = db_filename.rsplit('.', 1)[0] + "_version.json" if '.' in db_filename else db_filename + "_version.json"
        version_path = os.path.join(os.path.dirname(self.db_path), version_filename)

        # 3. Kiá»ƒm tra náº¿u file version cÅ© Ä‘Ã£ tá»“n táº¡i vÃ  hash chÆ°a Ä‘á»•i
        if os.path.exists(version_path):
            try:
                with open(version_path, "r", encoding="utf-8") as f:
                    old_info = json.load(f)
                    if old_info.get("version") == db_hash:
                        logger.info(f"ğŸ’¤ Version file khÃ´ng Ä‘á»•i ({db_hash}). Bá» qua ghi file json.")
                        return
            except Exception:
                # Náº¿u file cÅ© lá»—i, cá»© lá» Ä‘i vÃ  ghi má»›i
                pass

        # 4. Ghi file má»›i náº¿u hash khÃ¡c hoáº·c chÆ°a cÃ³ file
        version_info = {
            "version": db_hash,
            "generated_at": int(time.time())
        }
        
        with open(version_path, "w", encoding="utf-8") as f:
            json.dump(version_info, f)
        logger.info(f"ğŸ”– ÄÃ£ cáº­p nháº­t DB Version táº¡i: {version_path} (Hash: {db_hash})")

    def _files_are_identical(self, file1: str, file2: str) -> bool:
        """So sÃ¡nh hash MD5 cá»§a 2 file Ä‘á»ƒ xÃ¡c Ä‘á»‹nh ná»™i dung cÃ³ giá»‘ng nhau khÃ´ng."""
        import hashlib
        def get_hash(filepath):
            with open(filepath, "rb") as f:
                return hashlib.md5(f.read()).hexdigest()
        return get_hash(file1) == get_hash(file2)